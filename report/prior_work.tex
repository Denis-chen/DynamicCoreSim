The motivation for this paper came from the paper Amdahl's Law in the Multicore Era \cite{hill}. Here Amdahl's law was extended to cover different multiprocessing hardware models based on a limited budget of baseline hardware resources, or BCEs (Basic Core Equivalents). Based on both the percent of the workload that is parallelizable, the distribution of BCEss, and how performance of a single core scales, the paper gave new speedup curves to model system level hardware. The models used were Symmetric - an $n$x$n$ matrix of BCEs per core, Asymmetric - one large core and the rest small BCEs, and Dynamic - all BCEs switch between one large core and numerous small.

From there the curves were analyzed for a varying number of total BCEs and different fractions of parallel code, deriving results to consider for designing multicore systems. Among these results was that parallelism is still critical for achieving good speedups and increasing performance per core is globally efficient even if locally inefficient. Furthermore, dynamic systems are better than asymmetric, which in turn are better than symmetric. Based on Hill's conclusions that a dynamic system offered superior performance gain, we decided to investigate dynamic multiprocessing as an avenue to improve performance while maintaining power efficiency.